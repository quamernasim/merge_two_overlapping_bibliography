{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6095f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "STOPWORDS = [\"a\", \"an\", \"the\", \"on\", \"in\", \"of\", \"at\", \"for\", \"to\", \"from\", \"with\", \"about\"]\n",
    "\n",
    "def clean_title(title: str) -> str:\n",
    "    # Normalize and remove leading stopwords\n",
    "    title = title.strip()\n",
    "    # Use regex to remove ONLY at the start (case-insensitive)\n",
    "    return re.sub(rf\"^({'|'.join(STOPWORDS)})\\s+\", \"\", title, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98550a4",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c61af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bibtexparser\n",
    "\n",
    "# Load the .bib file\n",
    "with open(\"ref.bib\", \"r\", encoding=\"utf-8\") as bib_file:\n",
    "    bib_database = bibtexparser.load(bib_file)\n",
    "\n",
    "# Access all entries (as a list of dicts)\n",
    "for entry in bib_database.entries:\n",
    "    key = entry['ID']\n",
    "    year = entry.get('year')\n",
    "    title = entry.get('title')\n",
    "    author = entry.get('author')\n",
    "\n",
    "    prev = title\n",
    "    while True:\n",
    "        cleaned_title = clean_title(prev)\n",
    "        if prev == cleaned_title:\n",
    "            break\n",
    "        prev = cleaned_title\n",
    "\n",
    "    title_keyword = cleaned_title.split()[0].split('-')[0].split(':')[0].split(',')[0].split('.')[0].strip().lower()\n",
    "    author_keyword = author.split(',')[0].split('.')[0].split(' ')[0].split('-')[0].strip().lower()\n",
    "\n",
    "    reconsutructed_key = f\"{author_keyword}{year}{title_keyword}\"\n",
    "    if key!=reconsutructed_key:\n",
    "        # print(f\"Key mismatch: {reconsutructed_key} should be {key}\")\n",
    "        # if not key.startswith(f\"{author_keyword}{year}\"):\n",
    "        #     print(f\"Key prefix mismatch: {key} should start with {author_keyword}{year}\")\n",
    "        #     # break\n",
    "        if not key.endswith(f\"{title_keyword}\"):\n",
    "            print(f\"Key suffix mismatch: {key} should end with -----> {title_keyword}\")\n",
    "            break\n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201dc571",
   "metadata": {},
   "source": [
    "# Duplicate removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7950ef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries before deduplication: 158\n",
      "Total entries after deduplication: 147\n"
     ]
    }
   ],
   "source": [
    "import bibtexparser\n",
    "\n",
    "# Load the .bib file\n",
    "with open(\"ref.bib\", \"r\", encoding=\"utf-8\") as bib_file:\n",
    "    bib_database = bibtexparser.load(bib_file)\n",
    "\n",
    "entries = bib_database.entries\n",
    "print(f\"Total entries before deduplication: {len(entries)}\")\n",
    "\n",
    "# Deduplicate based on 'ID'\n",
    "seen_ids = set()\n",
    "unique_entries = []\n",
    "for entry in entries:\n",
    "    if entry['ID'] not in seen_ids:\n",
    "        unique_entries.append(entry)\n",
    "        seen_ids.add(entry['ID'])\n",
    "\n",
    "# Replace old entries with the deduplicated list\n",
    "bib_database.entries = unique_entries\n",
    "\n",
    "# Save the cleaned .bib file\n",
    "with open(\"ref_cleaned.bib\", \"w\", encoding=\"utf-8\") as bib_file:\n",
    "    bibtexparser.dump(bib_database, bib_file)\n",
    "\n",
    "print(f\"Total entries after deduplication: {len(unique_entries)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d97c107",
   "metadata": {},
   "source": [
    "# New bib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd2103b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bibtexparser\n",
    "\n",
    "# Load the .bib file\n",
    "with open(\"export.bib\", \"r\", encoding=\"utf-8\") as bib_file:\n",
    "    bib_database = bibtexparser.load(bib_file)\n",
    "\n",
    "# Access all entries (as a list of dicts)\n",
    "for entry in bib_database.entries:\n",
    "    key = entry['ID']\n",
    "    year = entry.get('year')\n",
    "    title = entry.get('title')\n",
    "    author = \" and \".join([f\"{i.split(' ')[-1]}, {\" \".join(i.split(' ')[:-1])}\" for i in entry.get('author').split(' and ')])\n",
    "    prev = title\n",
    "    while True:\n",
    "        cleaned_title = clean_title(prev)\n",
    "        if prev == cleaned_title:\n",
    "            break\n",
    "        prev = cleaned_title\n",
    "\n",
    "    title_keyword = cleaned_title.split()[0].split('-')[0].split(':')[0].split(',')[0].split('.')[0].strip().lower()\n",
    "    author_keyword = author.split(',')[0].split('.')[0].split(' ')[0].split('-')[0].strip().lower()\n",
    "\n",
    "    reconsutructed_key = f\"{author_keyword}{year}{title_keyword}\"\n",
    "    entry['author'] = author\n",
    "    entry['ID'] = reconsutructed_key\n",
    "\n",
    "with open(\"export_renamed.bib\", \"w\", encoding=\"utf-8\") as bib_file:\n",
    "    bibtexparser.dump(bib_database, bib_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f62f656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries before deduplication: 355\n",
      "Total entries after deduplication: 265\n"
     ]
    }
   ],
   "source": [
    "import bibtexparser\n",
    "\n",
    "# Load the .bib file\n",
    "with open(\"ref_unified.bib\", \"r\", encoding=\"utf-8\") as bib_file:\n",
    "    bib_database = bibtexparser.load(bib_file)\n",
    "\n",
    "entries = bib_database.entries\n",
    "print(f\"Total entries before deduplication: {len(entries)}\")\n",
    "\n",
    "# Deduplicate based on 'ID'\n",
    "seen_ids = set()\n",
    "unique_entries = []\n",
    "for entry in entries:\n",
    "    if entry['ID'] not in seen_ids:\n",
    "        unique_entries.append(entry)\n",
    "        seen_ids.add(entry['ID'])\n",
    "\n",
    "# Replace old entries with the deduplicated list\n",
    "bib_database.entries = unique_entries\n",
    "\n",
    "# Save the cleaned .bib file\n",
    "with open(\"ref_unified_cleaned.bib\", \"w\", encoding=\"utf-8\") as bib_file:\n",
    "    bibtexparser.dump(bib_database, bib_file)\n",
    "\n",
    "print(f\"Total entries after deduplication: {len(unique_entries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e90a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
